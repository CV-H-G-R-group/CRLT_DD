2023-12-05 04:25:45,909 - eval_it_pool: [0, 2000, 4000]
2023-12-05 04:25:51,153 - 
================== Exp 0 ==================
 
2023-12-05 04:25:51,153 - Hyper-parameters: 
 {'dataset': 'CIFAR100-head', 'model': 'ConvNet', 'ipc': 50, 'eval_mode': 'SS', 'num_exp': 5, 'num_eval': 5, 'epoch_eval_train': 500, 'Iteration': 4000, 'lr_img': 1.0, 'lr_net': 0.01, 'batch_real': 128, 'batch_train': 128, 'init': 'real', 'dsa_strategy': 'color_crop_cutout_flip_scale_rotate', 'data_path': 'data', 'save_path': 'result', 'dis_metric': 'ours', 'partial_condense': 'T', 'imb_type': 'exp', 'imb_factor': 0.01, 'add_pretrain': 'F', 'method': 'DM', 'device': 'cuda', 'dsa_param': <utils.ParamDiffAug object at 0x7fd2ecd73588>, 'dsa': True}
2023-12-05 04:25:51,154 - Evaluation model pool: ['ConvNet']
2023-12-05 04:25:55,703 - class c = 0: 500 real images
2023-12-05 04:25:55,704 - class c = 1: 477 real images
2023-12-05 04:25:55,704 - class c = 2: 455 real images
2023-12-05 04:25:55,705 - class c = 3: 434 real images
2023-12-05 04:25:55,706 - class c = 4: 415 real images
2023-12-05 04:25:55,707 - class c = 5: 396 real images
2023-12-05 04:25:55,708 - class c = 6: 378 real images
2023-12-05 04:25:55,710 - class c = 7: 361 real images
2023-12-05 04:25:55,712 - class c = 8: 344 real images
2023-12-05 04:25:55,713 - class c = 9: 328 real images
2023-12-05 04:25:55,714 - class c = 10: 314 real images
2023-12-05 04:25:55,716 - class c = 11: 299 real images
2023-12-05 04:25:55,717 - class c = 12: 286 real images
2023-12-05 04:25:55,718 - class c = 13: 273 real images
2023-12-05 04:25:55,720 - class c = 14: 260 real images
2023-12-05 04:25:55,721 - class c = 15: 248 real images
2023-12-05 04:25:55,722 - class c = 16: 237 real images
2023-12-05 04:25:55,723 - class c = 17: 226 real images
2023-12-05 04:25:55,724 - class c = 18: 216 real images
2023-12-05 04:25:55,726 - class c = 19: 206 real images
2023-12-05 04:25:55,726 - class c = 20: 197 real images
2023-12-05 04:25:55,728 - class c = 21: 188 real images
2023-12-05 04:25:55,729 - class c = 22: 179 real images
2023-12-05 04:25:55,730 - class c = 23: 171 real images
2023-12-05 04:25:55,733 - class c = 24: 163 real images
2023-12-05 04:25:55,734 - class c = 25: 156 real images
2023-12-05 04:25:55,736 - class c = 26: 149 real images
2023-12-05 04:25:55,738 - class c = 27: 142 real images
2023-12-05 04:25:55,739 - class c = 28: 135 real images
2023-12-05 04:25:55,741 - class c = 29: 129 real images
2023-12-05 04:25:55,743 - class c = 30: 123 real images
2023-12-05 04:25:55,744 - class c = 31: 118 real images
2023-12-05 04:25:55,746 - class c = 32: 112 real images
2023-12-05 04:25:55,746 - class c = 33: 107 real images
2023-12-05 04:25:55,747 - class c = 34: 102 real images
2023-12-05 04:25:55,749 - class c = 35: 98 real images
2023-12-05 04:25:55,751 - class c = 36: 93 real images
2023-12-05 04:25:55,752 - class c = 37: 89 real images
2023-12-05 04:25:55,753 - class c = 38: 85 real images
2023-12-05 04:25:55,755 - class c = 39: 81 real images
2023-12-05 04:25:55,756 - class c = 40: 77 real images
2023-12-05 04:25:55,758 - class c = 41: 74 real images
2023-12-05 04:25:55,760 - class c = 42: 70 real images
2023-12-05 04:25:55,760 - class c = 43: 67 real images
2023-12-05 04:25:55,761 - class c = 44: 64 real images
2023-12-05 04:25:55,762 - class c = 45: 61 real images
2023-12-05 04:25:55,763 - class c = 46: 58 real images
2023-12-05 04:25:55,765 - class c = 47: 56 real images
2023-12-05 04:25:55,766 - class c = 48: 53 real images
2023-12-05 04:25:55,767 - class c = 49: 51 real images
2023-12-05 04:25:55,769 - real images channel 0, mean = 0.1709, std = 1.3306
2023-12-05 04:25:55,771 - real images channel 1, mean = 0.0634, std = 1.3203
2023-12-05 04:25:55,772 - real images channel 2, mean = -0.0100, std = 1.3895
2023-12-05 04:25:55,777 - initialize synthetic data from random real images
2023-12-05 04:25:55,787 - [2023-12-05 04:25:55] training begins
2023-12-05 04:25:55,787 - -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 0
2023-12-05 04:25:55,789 - DSA augmentation strategy: 
 color_crop_cutout_flip_scale_rotate
2023-12-05 04:25:55,791 - DSA augmentation parameters: 
 {'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5}
2023-12-05 04:29:48,375 - [2023-12-05 04:29:48] Evaluate_00: epoch = 0500 train time = 229 s train loss = 0.037999 train acc = 0.9962, test acc = 0.2778
2023-12-05 04:33:42,289 - [2023-12-05 04:33:42] Evaluate_01: epoch = 0500 train time = 231 s train loss = 0.035999 train acc = 0.9965, test acc = 0.2820
2023-12-05 04:37:36,690 - [2023-12-05 04:37:36] Evaluate_02: epoch = 0500 train time = 231 s train loss = 0.040352 train acc = 0.9954, test acc = 0.2871
2023-12-05 04:41:30,605 - [2023-12-05 04:41:30] Evaluate_03: epoch = 0500 train time = 231 s train loss = 0.035560 train acc = 0.9956, test acc = 0.2852
2023-12-05 04:45:24,518 - [2023-12-05 04:45:24] Evaluate_04: epoch = 0500 train time = 231 s train loss = 0.040514 train acc = 0.9956, test acc = 0.2840
2023-12-05 04:45:24,519 - Evaluate 5 random ConvNet, mean = 0.2832 std = 0.0032
-------------------------
2023-12-05 04:49:52,863 - eval_it_pool: [2000, 4000]
2023-12-05 04:49:57,980 - 
================== Exp 0 ==================
 
2023-12-05 04:49:57,980 - Hyper-parameters: 
 {'dataset': 'CIFAR100-head', 'model': 'ConvNet', 'ipc': 50, 'eval_mode': 'SS', 'num_exp': 5, 'num_eval': 5, 'epoch_eval_train': 500, 'Iteration': 4000, 'lr_img': 1.0, 'lr_net': 0.01, 'batch_real': 128, 'batch_train': 128, 'init': 'real', 'dsa_strategy': 'color_crop_cutout_flip_scale_rotate', 'data_path': 'data', 'save_path': 'result', 'dis_metric': 'ours', 'partial_condense': 'T', 'imb_type': 'exp', 'imb_factor': 0.01, 'add_pretrain': 'F', 'method': 'DM', 'device': 'cuda', 'dsa_param': <utils.ParamDiffAug object at 0x7f90be8d15f8>, 'dsa': True}
2023-12-05 04:49:57,981 - Evaluation model pool: ['ConvNet']
2023-12-05 04:50:02,522 - class c = 0: 500 real images
2023-12-05 04:50:02,522 - class c = 1: 477 real images
2023-12-05 04:50:02,522 - class c = 2: 455 real images
2023-12-05 04:50:02,523 - class c = 3: 434 real images
2023-12-05 04:50:02,523 - class c = 4: 415 real images
2023-12-05 04:50:02,524 - class c = 5: 396 real images
2023-12-05 04:50:02,524 - class c = 6: 378 real images
2023-12-05 04:50:02,525 - class c = 7: 361 real images
2023-12-05 04:50:02,526 - class c = 8: 344 real images
2023-12-05 04:50:02,526 - class c = 9: 328 real images
2023-12-05 04:50:02,526 - class c = 10: 314 real images
2023-12-05 04:50:02,526 - class c = 11: 299 real images
2023-12-05 04:50:02,527 - class c = 12: 286 real images
2023-12-05 04:50:02,527 - class c = 13: 273 real images
2023-12-05 04:50:02,528 - class c = 14: 260 real images
2023-12-05 04:50:02,528 - class c = 15: 248 real images
2023-12-05 04:50:02,529 - class c = 16: 237 real images
2023-12-05 04:50:02,529 - class c = 17: 226 real images
2023-12-05 04:50:02,529 - class c = 18: 216 real images
2023-12-05 04:50:02,529 - class c = 19: 206 real images
2023-12-05 04:50:02,530 - class c = 20: 197 real images
2023-12-05 04:50:02,530 - class c = 21: 188 real images
2023-12-05 04:50:02,530 - class c = 22: 179 real images
2023-12-05 04:50:02,530 - class c = 23: 171 real images
2023-12-05 04:50:02,531 - class c = 24: 163 real images
2023-12-05 04:50:02,531 - class c = 25: 156 real images
2023-12-05 04:50:02,531 - class c = 26: 149 real images
2023-12-05 04:50:02,531 - class c = 27: 142 real images
2023-12-05 04:50:02,531 - class c = 28: 135 real images
2023-12-05 04:50:02,532 - class c = 29: 129 real images
2023-12-05 04:50:02,532 - class c = 30: 123 real images
2023-12-05 04:50:02,532 - class c = 31: 118 real images
2023-12-05 04:50:02,532 - class c = 32: 112 real images
2023-12-05 04:50:02,533 - class c = 33: 107 real images
2023-12-05 04:50:02,533 - class c = 34: 102 real images
2023-12-05 04:50:02,533 - class c = 35: 98 real images
2023-12-05 04:50:02,533 - class c = 36: 93 real images
2023-12-05 04:50:02,534 - class c = 37: 89 real images
2023-12-05 04:50:02,534 - class c = 38: 85 real images
2023-12-05 04:50:02,534 - class c = 39: 81 real images
2023-12-05 04:50:02,535 - class c = 40: 77 real images
2023-12-05 04:50:02,535 - class c = 41: 74 real images
2023-12-05 04:50:02,535 - class c = 42: 70 real images
2023-12-05 04:50:02,535 - class c = 43: 67 real images
2023-12-05 04:50:02,535 - class c = 44: 64 real images
2023-12-05 04:50:02,536 - class c = 45: 61 real images
2023-12-05 04:50:02,536 - class c = 46: 58 real images
2023-12-05 04:50:02,536 - class c = 47: 56 real images
2023-12-05 04:50:02,536 - class c = 48: 53 real images
2023-12-05 04:50:02,536 - class c = 49: 51 real images
2023-12-05 04:50:02,537 - real images channel 0, mean = 0.1692, std = 1.3291
2023-12-05 04:50:02,538 - real images channel 1, mean = 0.0608, std = 1.3208
2023-12-05 04:50:02,538 - real images channel 2, mean = -0.0078, std = 1.3888
2023-12-05 04:50:02,540 - initialize synthetic data from random real images
2023-12-05 04:50:02,547 - [2023-12-05 04:50:02] training begins
2023-12-05 04:50:03,217 - [2023-12-05 04:50:03] iter = 00000, loss = 3.9932
2023-12-05 04:50:10,629 - [2023-12-05 04:50:10] iter = 00010, loss = 3.8530
2023-12-05 04:50:18,066 - [2023-12-05 04:50:18] iter = 00020, loss = 3.1030
2023-12-05 04:50:25,550 - [2023-12-05 04:50:25] iter = 00030, loss = 3.0150
2023-12-05 04:50:33,062 - [2023-12-05 04:50:33] iter = 00040, loss = 2.8112
2023-12-05 04:50:40,600 - [2023-12-05 04:50:40] iter = 00050, loss = 2.4700
2023-12-05 04:50:48,126 - [2023-12-05 04:50:48] iter = 00060, loss = 2.4480
2023-12-05 04:50:55,676 - [2023-12-05 04:50:55] iter = 00070, loss = 2.3948
2023-12-05 04:51:03,226 - [2023-12-05 04:51:03] iter = 00080, loss = 2.2775
2023-12-05 04:51:10,720 - [2023-12-05 04:51:10] iter = 00090, loss = 2.1313
2023-12-05 04:51:18,225 - [2023-12-05 04:51:18] iter = 00100, loss = 2.1289
2023-12-05 04:51:25,787 - [2023-12-05 04:51:25] iter = 00110, loss = 2.0126
2023-12-05 04:51:33,507 - [2023-12-05 04:51:33] iter = 00120, loss = 2.0923
2023-12-05 04:51:41,536 - [2023-12-05 04:51:41] iter = 00130, loss = 1.9283
2023-12-05 04:51:49,713 - [2023-12-05 04:51:49] iter = 00140, loss = 1.8380
2023-12-05 04:51:57,914 - [2023-12-05 04:51:57] iter = 00150, loss = 1.8659
2023-12-05 04:52:06,266 - [2023-12-05 04:52:06] iter = 00160, loss = 1.7806
2023-12-05 04:52:14,581 - [2023-12-05 04:52:14] iter = 00170, loss = 1.8113
2023-12-05 04:52:22,983 - [2023-12-05 04:52:22] iter = 00180, loss = 1.7203
2023-12-05 04:52:31,296 - [2023-12-05 04:52:31] iter = 00190, loss = 1.7341
2023-12-05 04:52:39,399 - [2023-12-05 04:52:39] iter = 00200, loss = 1.6360
2023-12-05 04:52:47,640 - [2023-12-05 04:52:47] iter = 00210, loss = 1.6781
2023-12-05 04:52:55,803 - [2023-12-05 04:52:55] iter = 00220, loss = 1.7114
2023-12-05 04:53:04,002 - [2023-12-05 04:53:03] iter = 00230, loss = 1.6046
2023-12-05 04:53:12,235 - [2023-12-05 04:53:12] iter = 00240, loss = 1.5670
2023-12-05 04:53:20,509 - [2023-12-05 04:53:20] iter = 00250, loss = 1.6087
2023-12-05 04:53:28,690 - [2023-12-05 04:53:28] iter = 00260, loss = 1.6775
2023-12-05 04:53:36,832 - [2023-12-05 04:53:36] iter = 00270, loss = 1.5881
2023-12-05 04:53:44,930 - [2023-12-05 04:53:44] iter = 00280, loss = 1.5290
2023-12-05 04:53:53,105 - [2023-12-05 04:53:53] iter = 00290, loss = 1.5296
2023-12-05 04:54:01,282 - [2023-12-05 04:54:01] iter = 00300, loss = 1.5496
2023-12-05 04:54:09,442 - [2023-12-05 04:54:09] iter = 00310, loss = 1.4969
2023-12-05 04:54:17,634 - [2023-12-05 04:54:17] iter = 00320, loss = 1.5669
2023-12-05 04:54:25,699 - [2023-12-05 04:54:25] iter = 00330, loss = 1.5931
2023-12-05 04:54:33,787 - [2023-12-05 04:54:33] iter = 00340, loss = 1.5684
2023-12-05 04:54:41,948 - [2023-12-05 04:54:41] iter = 00350, loss = 1.4647
2023-12-05 04:54:50,067 - [2023-12-05 04:54:50] iter = 00360, loss = 1.5158
2023-12-05 04:54:58,250 - [2023-12-05 04:54:58] iter = 00370, loss = 1.4898
2023-12-05 04:55:06,332 - [2023-12-05 04:55:06] iter = 00380, loss = 1.4988
2023-12-05 04:55:14,475 - [2023-12-05 04:55:14] iter = 00390, loss = 1.4278
2023-12-05 04:55:22,602 - [2023-12-05 04:55:22] iter = 00400, loss = 1.5464
2023-12-05 04:55:30,805 - [2023-12-05 04:55:30] iter = 00410, loss = 1.5014
2023-12-05 04:55:38,944 - [2023-12-05 04:55:38] iter = 00420, loss = 1.5090
2023-12-05 04:55:47,151 - [2023-12-05 04:55:47] iter = 00430, loss = 1.4343
2023-12-05 04:55:55,292 - [2023-12-05 04:55:55] iter = 00440, loss = 1.5094
2023-12-05 04:56:03,533 - [2023-12-05 04:56:03] iter = 00450, loss = 1.4480
2023-12-05 04:56:11,755 - [2023-12-05 04:56:11] iter = 00460, loss = 1.6080
2023-12-05 04:56:20,015 - [2023-12-05 04:56:20] iter = 00470, loss = 1.4449
2023-12-05 04:56:28,291 - [2023-12-05 04:56:28] iter = 00480, loss = 1.4314
2023-12-05 04:56:36,555 - [2023-12-05 04:56:36] iter = 00490, loss = 1.3771
2023-12-05 04:56:44,896 - [2023-12-05 04:56:44] iter = 00500, loss = 1.4980
2023-12-05 04:56:53,386 - [2023-12-05 04:56:53] iter = 00510, loss = 1.4119
2023-12-05 04:57:01,553 - [2023-12-05 04:57:01] iter = 00520, loss = 1.3886
2023-12-05 04:57:09,937 - [2023-12-05 04:57:09] iter = 00530, loss = 1.4234
2023-12-05 04:57:18,436 - [2023-12-05 04:57:18] iter = 00540, loss = 1.3490
2023-12-05 04:57:26,953 - [2023-12-05 04:57:26] iter = 00550, loss = 1.4187
2023-12-05 04:57:35,268 - [2023-12-05 04:57:35] iter = 00560, loss = 1.3666
2023-12-05 04:57:43,579 - [2023-12-05 04:57:43] iter = 00570, loss = 1.3959
2023-12-05 04:57:52,040 - [2023-12-05 04:57:52] iter = 00580, loss = 1.4441
2023-12-05 04:58:00,737 - [2023-12-05 04:58:00] iter = 00590, loss = 1.4814
2023-12-05 04:58:08,946 - [2023-12-05 04:58:08] iter = 00600, loss = 1.3893
2023-12-05 04:58:17,574 - [2023-12-05 04:58:17] iter = 00610, loss = 1.3440
2023-12-05 04:58:26,191 - [2023-12-05 04:58:26] iter = 00620, loss = 1.3670
2023-12-05 04:58:34,427 - [2023-12-05 04:58:34] iter = 00630, loss = 1.3796
2023-12-05 04:58:42,813 - [2023-12-05 04:58:42] iter = 00640, loss = 1.3533
2023-12-05 04:58:51,359 - [2023-12-05 04:58:51] iter = 00650, loss = 1.3129
2023-12-05 04:58:59,874 - [2023-12-05 04:58:59] iter = 00660, loss = 1.3175
2023-12-05 04:59:08,114 - [2023-12-05 04:59:08] iter = 00670, loss = 1.3511
2023-12-05 04:59:16,346 - [2023-12-05 04:59:16] iter = 00680, loss = 1.3470
2023-12-05 04:59:24,406 - [2023-12-05 04:59:24] iter = 00690, loss = 1.3495
2023-12-05 04:59:32,607 - [2023-12-05 04:59:32] iter = 00700, loss = 1.3375
2023-12-05 04:59:40,926 - [2023-12-05 04:59:40] iter = 00710, loss = 1.3684
2023-12-05 04:59:49,085 - [2023-12-05 04:59:49] iter = 00720, loss = 1.3617
2023-12-05 04:59:57,248 - [2023-12-05 04:59:57] iter = 00730, loss = 1.3818
2023-12-05 05:00:05,400 - [2023-12-05 05:00:05] iter = 00740, loss = 1.3273
2023-12-05 05:00:13,756 - [2023-12-05 05:00:13] iter = 00750, loss = 1.2517
2023-12-05 05:00:22,207 - [2023-12-05 05:00:22] iter = 00760, loss = 1.3309
2023-12-05 05:00:30,943 - [2023-12-05 05:00:30] iter = 00770, loss = 1.3085
2023-12-05 05:00:39,922 - [2023-12-05 05:00:39] iter = 00780, loss = 1.2504
2023-12-05 05:00:48,836 - [2023-12-05 05:00:48] iter = 00790, loss = 1.3486
2023-12-05 05:00:57,319 - [2023-12-05 05:00:57] iter = 00800, loss = 1.3404
2023-12-05 05:01:05,648 - [2023-12-05 05:01:05] iter = 00810, loss = 1.3527
2023-12-05 05:01:14,036 - [2023-12-05 05:01:14] iter = 00820, loss = 1.2820
2023-12-05 05:01:22,516 - [2023-12-05 05:01:22] iter = 00830, loss = 1.2975
2023-12-05 05:01:30,924 - [2023-12-05 05:01:30] iter = 00840, loss = 1.3170
2023-12-05 05:01:39,259 - [2023-12-05 05:01:39] iter = 00850, loss = 1.2397
2023-12-05 05:01:47,725 - [2023-12-05 05:01:47] iter = 00860, loss = 1.3191
2023-12-05 05:01:56,133 - [2023-12-05 05:01:56] iter = 00870, loss = 1.2785
2023-12-05 05:02:04,609 - [2023-12-05 05:02:04] iter = 00880, loss = 1.2923
2023-12-05 05:02:13,043 - [2023-12-05 05:02:13] iter = 00890, loss = 1.2813
2023-12-05 05:02:21,431 - [2023-12-05 05:02:21] iter = 00900, loss = 1.2595
2023-12-05 05:02:29,782 - [2023-12-05 05:02:29] iter = 00910, loss = 1.2144
2023-12-05 05:02:38,134 - [2023-12-05 05:02:38] iter = 00920, loss = 1.3630
2023-12-05 05:02:46,498 - [2023-12-05 05:02:46] iter = 00930, loss = 1.2350
2023-12-05 05:02:54,918 - [2023-12-05 05:02:54] iter = 00940, loss = 1.2783
2023-12-05 05:03:03,341 - [2023-12-05 05:03:03] iter = 00950, loss = 1.2531
2023-12-05 05:03:11,685 - [2023-12-05 05:03:11] iter = 00960, loss = 1.2888
2023-12-05 05:03:20,190 - [2023-12-05 05:03:20] iter = 00970, loss = 1.2010
2023-12-05 05:03:28,574 - [2023-12-05 05:03:28] iter = 00980, loss = 1.2653
2023-12-05 05:03:37,011 - [2023-12-05 05:03:37] iter = 00990, loss = 1.2573
2023-12-05 05:03:45,333 - [2023-12-05 05:03:45] iter = 01000, loss = 1.1886
2023-12-05 05:03:53,795 - [2023-12-05 05:03:53] iter = 01010, loss = 1.2073
2023-12-05 05:04:02,404 - [2023-12-05 05:04:02] iter = 01020, loss = 1.2488
2023-12-05 05:04:10,823 - [2023-12-05 05:04:10] iter = 01030, loss = 1.2519
2023-12-05 05:04:19,398 - [2023-12-05 05:04:19] iter = 01040, loss = 1.1693
2023-12-05 05:04:27,842 - [2023-12-05 05:04:27] iter = 01050, loss = 1.2154
2023-12-05 05:04:36,192 - [2023-12-05 05:04:36] iter = 01060, loss = 1.2743
2023-12-05 05:04:44,516 - [2023-12-05 05:04:44] iter = 01070, loss = 1.2146
2023-12-05 05:04:52,844 - [2023-12-05 05:04:52] iter = 01080, loss = 1.2263
2023-12-05 05:05:01,303 - [2023-12-05 05:05:01] iter = 01090, loss = 1.2701
2023-12-05 05:05:09,787 - [2023-12-05 05:05:09] iter = 01100, loss = 1.2649
2023-12-05 05:05:18,280 - [2023-12-05 05:05:18] iter = 01110, loss = 1.2550
2023-12-05 05:05:26,680 - [2023-12-05 05:05:26] iter = 01120, loss = 1.1981
2023-12-05 05:05:35,142 - [2023-12-05 05:05:35] iter = 01130, loss = 1.2676
2023-12-05 05:05:43,491 - [2023-12-05 05:05:43] iter = 01140, loss = 1.2063
2023-12-05 05:05:52,041 - [2023-12-05 05:05:52] iter = 01150, loss = 1.2190
2023-12-05 05:06:00,618 - [2023-12-05 05:06:00] iter = 01160, loss = 1.2623
2023-12-05 05:06:08,739 - [2023-12-05 05:06:08] iter = 01170, loss = 1.2050
2023-12-05 05:06:16,912 - [2023-12-05 05:06:16] iter = 01180, loss = 1.2223
2023-12-05 05:06:25,100 - [2023-12-05 05:06:25] iter = 01190, loss = 1.2111
2023-12-05 05:06:33,366 - [2023-12-05 05:06:33] iter = 01200, loss = 1.2186
2023-12-05 05:06:41,499 - [2023-12-05 05:06:41] iter = 01210, loss = 1.2052
2023-12-05 05:06:49,639 - [2023-12-05 05:06:49] iter = 01220, loss = 1.1981
2023-12-05 05:06:57,905 - [2023-12-05 05:06:57] iter = 01230, loss = 1.2493
2023-12-05 05:07:06,046 - [2023-12-05 05:07:06] iter = 01240, loss = 1.2625
2023-12-05 05:07:14,294 - [2023-12-05 05:07:14] iter = 01250, loss = 1.2038
2023-12-05 05:07:22,476 - [2023-12-05 05:07:22] iter = 01260, loss = 1.2416
2023-12-05 05:07:30,605 - [2023-12-05 05:07:30] iter = 01270, loss = 1.2341
2023-12-05 05:07:38,770 - [2023-12-05 05:07:38] iter = 01280, loss = 1.1866
2023-12-05 05:07:46,993 - [2023-12-05 05:07:46] iter = 01290, loss = 1.2143
2023-12-05 05:07:55,230 - [2023-12-05 05:07:55] iter = 01300, loss = 1.1925
2023-12-05 05:08:03,476 - [2023-12-05 05:08:03] iter = 01310, loss = 1.1710
2023-12-05 05:08:11,764 - [2023-12-05 05:08:11] iter = 01320, loss = 1.2893
2023-12-05 05:08:19,997 - [2023-12-05 05:08:19] iter = 01330, loss = 1.1579
2023-12-05 05:08:28,243 - [2023-12-05 05:08:28] iter = 01340, loss = 1.1997
2023-12-05 05:08:36,461 - [2023-12-05 05:08:36] iter = 01350, loss = 1.2020
2023-12-05 05:08:44,830 - [2023-12-05 05:08:44] iter = 01360, loss = 1.2203
2023-12-05 05:08:53,151 - [2023-12-05 05:08:53] iter = 01370, loss = 1.2278
2023-12-05 05:09:01,386 - [2023-12-05 05:09:01] iter = 01380, loss = 1.1626
2023-12-05 05:09:09,544 - [2023-12-05 05:09:09] iter = 01390, loss = 1.2852
2023-12-05 05:09:17,852 - [2023-12-05 05:09:17] iter = 01400, loss = 1.1996
2023-12-05 05:09:26,135 - [2023-12-05 05:09:26] iter = 01410, loss = 1.2153
2023-12-05 05:09:34,353 - [2023-12-05 05:09:34] iter = 01420, loss = 1.2482
2023-12-05 05:09:42,611 - [2023-12-05 05:09:42] iter = 01430, loss = 1.2122
2023-12-05 05:09:50,815 - [2023-12-05 05:09:50] iter = 01440, loss = 1.1831
2023-12-05 05:09:59,013 - [2023-12-05 05:09:59] iter = 01450, loss = 1.1799
2023-12-05 05:10:07,341 - [2023-12-05 05:10:07] iter = 01460, loss = 1.1785
2023-12-05 05:10:15,663 - [2023-12-05 05:10:15] iter = 01470, loss = 1.2245
2023-12-05 05:10:23,828 - [2023-12-05 05:10:23] iter = 01480, loss = 1.1882
2023-12-05 05:10:31,981 - [2023-12-05 05:10:31] iter = 01490, loss = 1.2192
2023-12-05 05:10:40,239 - [2023-12-05 05:10:40] iter = 01500, loss = 1.1525
2023-12-05 05:10:48,545 - [2023-12-05 05:10:48] iter = 01510, loss = 1.1782
2023-12-05 05:10:56,753 - [2023-12-05 05:10:56] iter = 01520, loss = 1.2350
2023-12-05 05:11:04,926 - [2023-12-05 05:11:04] iter = 01530, loss = 1.2229
2023-12-05 05:11:13,128 - [2023-12-05 05:11:13] iter = 01540, loss = 1.1759
2023-12-05 05:11:21,456 - [2023-12-05 05:11:21] iter = 01550, loss = 1.1455
2023-12-05 05:11:29,710 - [2023-12-05 05:11:29] iter = 01560, loss = 1.1618
2023-12-05 05:11:37,924 - [2023-12-05 05:11:37] iter = 01570, loss = 1.1941
2023-12-05 05:11:46,257 - [2023-12-05 05:11:46] iter = 01580, loss = 1.2055
2023-12-05 05:11:54,577 - [2023-12-05 05:11:54] iter = 01590, loss = 1.2158
2023-12-05 05:12:02,757 - [2023-12-05 05:12:02] iter = 01600, loss = 1.1474
2023-12-05 05:12:11,000 - [2023-12-05 05:12:10] iter = 01610, loss = 1.1410
2023-12-05 05:12:19,253 - [2023-12-05 05:12:19] iter = 01620, loss = 1.1178
2023-12-05 05:12:27,548 - [2023-12-05 05:12:27] iter = 01630, loss = 1.2641
2023-12-05 05:12:35,890 - [2023-12-05 05:12:35] iter = 01640, loss = 1.1502
2023-12-05 05:12:44,238 - [2023-12-05 05:12:44] iter = 01650, loss = 1.1498
2023-12-05 05:12:52,538 - [2023-12-05 05:12:52] iter = 01660, loss = 1.1307
2023-12-05 05:13:00,822 - [2023-12-05 05:13:00] iter = 01670, loss = 1.1734
2023-12-05 05:13:09,142 - [2023-12-05 05:13:09] iter = 01680, loss = 1.2311
2023-12-05 05:13:17,507 - [2023-12-05 05:13:17] iter = 01690, loss = 1.1871
2023-12-05 05:13:25,741 - [2023-12-05 05:13:25] iter = 01700, loss = 1.2088
2023-12-05 05:13:33,986 - [2023-12-05 05:13:33] iter = 01710, loss = 1.1968
2023-12-05 05:13:42,185 - [2023-12-05 05:13:42] iter = 01720, loss = 1.1397
2023-12-05 05:13:50,431 - [2023-12-05 05:13:50] iter = 01730, loss = 1.1410
2023-12-05 05:13:58,741 - [2023-12-05 05:13:58] iter = 01740, loss = 1.1108
2023-12-05 05:14:06,925 - [2023-12-05 05:14:06] iter = 01750, loss = 1.1632
2023-12-05 05:14:15,170 - [2023-12-05 05:14:15] iter = 01760, loss = 1.1741
2023-12-05 05:14:23,459 - [2023-12-05 05:14:23] iter = 01770, loss = 1.0888
2023-12-05 05:14:31,776 - [2023-12-05 05:14:31] iter = 01780, loss = 1.1880
2023-12-05 05:14:40,007 - [2023-12-05 05:14:40] iter = 01790, loss = 1.1322
2023-12-05 05:14:48,234 - [2023-12-05 05:14:48] iter = 01800, loss = 1.1538
2023-12-05 05:14:56,457 - [2023-12-05 05:14:56] iter = 01810, loss = 1.2052
2023-12-05 05:15:04,807 - [2023-12-05 05:15:04] iter = 01820, loss = 1.1060
2023-12-05 05:15:13,081 - [2023-12-05 05:15:13] iter = 01830, loss = 1.1671
2023-12-05 05:15:21,451 - [2023-12-05 05:15:21] iter = 01840, loss = 1.1570
2023-12-05 05:15:29,631 - [2023-12-05 05:15:29] iter = 01850, loss = 1.1884
2023-12-05 05:15:37,885 - [2023-12-05 05:15:37] iter = 01860, loss = 1.1956
2023-12-05 05:15:46,125 - [2023-12-05 05:15:46] iter = 01870, loss = 1.1225
2023-12-05 05:15:54,346 - [2023-12-05 05:15:54] iter = 01880, loss = 1.1267
2023-12-05 05:16:02,682 - [2023-12-05 05:16:02] iter = 01890, loss = 1.1706
2023-12-05 05:16:11,052 - [2023-12-05 05:16:11] iter = 01900, loss = 1.1242
2023-12-05 05:16:19,260 - [2023-12-05 05:16:19] iter = 01910, loss = 1.1513
2023-12-05 05:16:27,499 - [2023-12-05 05:16:27] iter = 01920, loss = 1.1233
2023-12-05 05:16:35,835 - [2023-12-05 05:16:35] iter = 01930, loss = 1.1275
2023-12-05 05:16:44,112 - [2023-12-05 05:16:44] iter = 01940, loss = 1.2156
2023-12-05 05:16:52,384 - [2023-12-05 05:16:52] iter = 01950, loss = 1.1233
2023-12-05 05:17:00,676 - [2023-12-05 05:17:00] iter = 01960, loss = 1.1654
2023-12-05 05:17:08,852 - [2023-12-05 05:17:08] iter = 01970, loss = 1.1077
2023-12-05 05:17:17,203 - [2023-12-05 05:17:17] iter = 01980, loss = 1.1464
2023-12-05 05:17:25,424 - [2023-12-05 05:17:25] iter = 01990, loss = 1.1346
2023-12-05 05:17:32,874 - -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 2000
2023-12-05 05:17:32,874 - DSA augmentation strategy: 
 color_crop_cutout_flip_scale_rotate
2023-12-05 05:17:32,875 - DSA augmentation parameters: 
 {'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 52676}
2023-12-05 05:21:24,028 - [2023-12-05 05:21:24] Evaluate_00: epoch = 0500 train time = 228 s train loss = 0.036953 train acc = 0.9965, test acc = 0.2983
2023-12-05 05:25:15,083 - [2023-12-05 05:25:15] Evaluate_01: epoch = 0500 train time = 228 s train loss = 0.026237 train acc = 0.9983, test acc = 0.2990
2023-12-05 05:29:06,204 - [2023-12-05 05:29:06] Evaluate_02: epoch = 0500 train time = 228 s train loss = 0.031341 train acc = 0.9971, test acc = 0.3015
2023-12-05 05:32:57,352 - [2023-12-05 05:32:57] Evaluate_03: epoch = 0500 train time = 228 s train loss = 0.032913 train acc = 0.9974, test acc = 0.2933
2023-12-05 05:36:48,518 - [2023-12-05 05:36:48] Evaluate_04: epoch = 0500 train time = 228 s train loss = 0.037698 train acc = 0.9959, test acc = 0.2962
2023-12-05 05:36:48,519 - Evaluate 5 random ConvNet, mean = 0.2977 std = 0.0028
-------------------------
2023-12-05 05:36:50,483 - [2023-12-05 05:36:50] iter = 02000, loss = 1.1358
2023-12-05 05:36:58,806 - [2023-12-05 05:36:58] iter = 02010, loss = 1.1578
2023-12-05 05:37:07,111 - [2023-12-05 05:37:07] iter = 02020, loss = 1.1577
2023-12-05 05:37:15,462 - [2023-12-05 05:37:15] iter = 02030, loss = 1.1850
2023-12-05 05:37:23,711 - [2023-12-05 05:37:23] iter = 02040, loss = 1.1468
2023-12-05 05:37:32,033 - [2023-12-05 05:37:32] iter = 02050, loss = 1.2011
2023-12-05 05:37:40,423 - [2023-12-05 05:37:40] iter = 02060, loss = 1.1257
2023-12-05 05:37:48,692 - [2023-12-05 05:37:48] iter = 02070, loss = 1.1417
2023-12-05 05:37:57,105 - [2023-12-05 05:37:57] iter = 02080, loss = 1.1813
2023-12-05 05:38:05,320 - [2023-12-05 05:38:05] iter = 02090, loss = 1.1277
2023-12-05 05:38:13,612 - [2023-12-05 05:38:13] iter = 02100, loss = 1.1562
2023-12-05 05:38:21,970 - [2023-12-05 05:38:21] iter = 02110, loss = 1.0953
2023-12-05 05:38:30,324 - [2023-12-05 05:38:30] iter = 02120, loss = 1.1623
2023-12-05 05:38:38,538 - [2023-12-05 05:38:38] iter = 02130, loss = 1.1163
2023-12-05 05:38:46,770 - [2023-12-05 05:38:46] iter = 02140, loss = 1.1049
2023-12-05 05:38:55,047 - [2023-12-05 05:38:55] iter = 02150, loss = 1.1902
2023-12-05 05:39:03,281 - [2023-12-05 05:39:03] iter = 02160, loss = 1.1297
2023-12-05 05:39:11,679 - [2023-12-05 05:39:11] iter = 02170, loss = 1.1526
2023-12-05 05:39:19,967 - [2023-12-05 05:39:19] iter = 02180, loss = 1.1169
2023-12-05 05:39:28,398 - [2023-12-05 05:39:28] iter = 02190, loss = 1.1217
2023-12-05 05:39:36,691 - [2023-12-05 05:39:36] iter = 02200, loss = 1.1458
2023-12-05 05:39:44,863 - [2023-12-05 05:39:44] iter = 02210, loss = 1.0771
2023-12-05 05:39:53,207 - [2023-12-05 05:39:53] iter = 02220, loss = 1.1465
2023-12-05 05:40:01,540 - [2023-12-05 05:40:01] iter = 02230, loss = 1.0835
2023-12-05 05:40:10,049 - [2023-12-05 05:40:10] iter = 02240, loss = 1.1416
2023-12-05 05:40:18,369 - [2023-12-05 05:40:18] iter = 02250, loss = 1.1652
2023-12-05 05:40:26,726 - [2023-12-05 05:40:26] iter = 02260, loss = 1.0685
2023-12-05 05:40:35,098 - [2023-12-05 05:40:35] iter = 02270, loss = 1.1231
2023-12-05 05:40:43,441 - [2023-12-05 05:40:43] iter = 02280, loss = 1.0897
2023-12-05 05:40:51,746 - [2023-12-05 05:40:51] iter = 02290, loss = 1.1447
2023-12-05 05:41:00,122 - [2023-12-05 05:41:00] iter = 02300, loss = 1.1461
2023-12-05 05:41:08,407 - [2023-12-05 05:41:08] iter = 02310, loss = 1.1133
2023-12-05 05:41:16,869 - [2023-12-05 05:41:16] iter = 02320, loss = 1.1271
2023-12-05 05:41:25,275 - [2023-12-05 05:41:25] iter = 02330, loss = 1.1437
2023-12-05 05:41:33,663 - [2023-12-05 05:41:33] iter = 02340, loss = 1.1312
2023-12-05 05:41:42,109 - [2023-12-05 05:41:42] iter = 02350, loss = 1.1118
2023-12-05 05:41:50,392 - [2023-12-05 05:41:50] iter = 02360, loss = 1.1386
2023-12-05 05:41:58,731 - [2023-12-05 05:41:58] iter = 02370, loss = 1.0923
2023-12-05 05:42:07,036 - [2023-12-05 05:42:07] iter = 02380, loss = 1.1184
2023-12-05 05:42:15,368 - [2023-12-05 05:42:15] iter = 02390, loss = 1.0942
2023-12-05 05:42:23,905 - [2023-12-05 05:42:23] iter = 02400, loss = 1.1714
2023-12-05 05:42:32,311 - [2023-12-05 05:42:32] iter = 02410, loss = 1.1576
2023-12-05 05:42:40,714 - [2023-12-05 05:42:40] iter = 02420, loss = 1.1249
2023-12-05 05:42:49,042 - [2023-12-05 05:42:49] iter = 02430, loss = 1.1137
2023-12-05 05:42:57,406 - [2023-12-05 05:42:57] iter = 02440, loss = 1.1318
2023-12-05 05:43:05,739 - [2023-12-05 05:43:05] iter = 02450, loss = 1.1483
2023-12-05 05:43:14,135 - [2023-12-05 05:43:14] iter = 02460, loss = 1.1108
2023-12-05 05:43:22,490 - [2023-12-05 05:43:22] iter = 02470, loss = 1.0987
2023-12-05 05:43:30,824 - [2023-12-05 05:43:30] iter = 02480, loss = 1.1552
2023-12-05 05:43:39,238 - [2023-12-05 05:43:39] iter = 02490, loss = 1.0913
2023-12-05 05:43:47,631 - [2023-12-05 05:43:47] iter = 02500, loss = 1.0981
2023-12-05 05:43:55,960 - [2023-12-05 05:43:55] iter = 02510, loss = 1.0788
2023-12-05 05:44:04,330 - [2023-12-05 05:44:04] iter = 02520, loss = 1.0930
2023-12-05 05:44:12,754 - [2023-12-05 05:44:12] iter = 02530, loss = 1.1536
2023-12-05 05:44:21,069 - [2023-12-05 05:44:21] iter = 02540, loss = 1.0667
2023-12-05 05:44:29,564 - [2023-12-05 05:44:29] iter = 02550, loss = 1.0445
2023-12-05 05:44:37,974 - [2023-12-05 05:44:37] iter = 02560, loss = 1.0412
2023-12-05 05:44:46,301 - [2023-12-05 05:44:46] iter = 02570, loss = 1.0406
2023-12-05 05:44:54,711 - [2023-12-05 05:44:54] iter = 02580, loss = 1.0646
2023-12-05 05:45:02,957 - [2023-12-05 05:45:02] iter = 02590, loss = 1.0834
2023-12-05 05:45:11,185 - [2023-12-05 05:45:11] iter = 02600, loss = 1.1030
2023-12-05 05:45:19,557 - [2023-12-05 05:45:19] iter = 02610, loss = 1.0853
2023-12-05 05:45:27,834 - [2023-12-05 05:45:27] iter = 02620, loss = 1.0876
2023-12-05 05:45:36,231 - [2023-12-05 05:45:36] iter = 02630, loss = 1.1183
2023-12-05 05:45:44,561 - [2023-12-05 05:45:44] iter = 02640, loss = 1.0810
2023-12-05 05:45:52,851 - [2023-12-05 05:45:52] iter = 02650, loss = 1.1276
2023-12-05 05:46:01,181 - [2023-12-05 05:46:01] iter = 02660, loss = 1.1113
2023-12-05 05:46:09,438 - [2023-12-05 05:46:09] iter = 02670, loss = 1.1259
2023-12-05 05:46:17,853 - [2023-12-05 05:46:17] iter = 02680, loss = 1.0998
2023-12-05 05:46:26,277 - [2023-12-05 05:46:26] iter = 02690, loss = 1.0618
2023-12-05 05:46:34,671 - [2023-12-05 05:46:34] iter = 02700, loss = 1.1264
2023-12-05 05:46:43,055 - [2023-12-05 05:46:43] iter = 02710, loss = 1.1314
2023-12-05 05:46:51,384 - [2023-12-05 05:46:51] iter = 02720, loss = 1.0842
2023-12-05 05:46:59,892 - [2023-12-05 05:46:59] iter = 02730, loss = 1.1009
2023-12-05 05:47:08,089 - [2023-12-05 05:47:08] iter = 02740, loss = 1.0494
2023-12-05 05:47:16,465 - [2023-12-05 05:47:16] iter = 02750, loss = 1.1366
2023-12-05 05:47:24,862 - [2023-12-05 05:47:24] iter = 02760, loss = 1.1518
2023-12-05 05:47:33,246 - [2023-12-05 05:47:33] iter = 02770, loss = 1.0160
2023-12-05 05:47:41,726 - [2023-12-05 05:47:41] iter = 02780, loss = 1.1278
2023-12-05 05:47:50,147 - [2023-12-05 05:47:50] iter = 02790, loss = 1.1027
2023-12-05 05:47:58,498 - [2023-12-05 05:47:58] iter = 02800, loss = 1.1073
2023-12-05 05:48:06,863 - [2023-12-05 05:48:06] iter = 02810, loss = 1.1184
2023-12-05 05:48:14,984 - [2023-12-05 05:48:14] iter = 02820, loss = 1.1425
2023-12-05 05:48:23,529 - [2023-12-05 05:48:23] iter = 02830, loss = 1.0630
2023-12-05 05:48:31,937 - [2023-12-05 05:48:31] iter = 02840, loss = 1.0821
2023-12-05 05:48:40,432 - [2023-12-05 05:48:40] iter = 02850, loss = 1.1397
2023-12-05 05:48:48,852 - [2023-12-05 05:48:48] iter = 02860, loss = 1.0993
2023-12-05 05:48:57,214 - [2023-12-05 05:48:57] iter = 02870, loss = 1.0505
2023-12-05 05:49:05,565 - [2023-12-05 05:49:05] iter = 02880, loss = 1.0597
2023-12-05 05:49:13,870 - [2023-12-05 05:49:13] iter = 02890, loss = 1.0937
2023-12-05 05:49:22,139 - [2023-12-05 05:49:22] iter = 02900, loss = 1.0963
2023-12-05 05:49:30,497 - [2023-12-05 05:49:30] iter = 02910, loss = 1.0992
2023-12-05 05:49:38,873 - [2023-12-05 05:49:38] iter = 02920, loss = 1.0841
2023-12-05 05:49:47,277 - [2023-12-05 05:49:47] iter = 02930, loss = 1.1106
2023-12-05 05:49:55,632 - [2023-12-05 05:49:55] iter = 02940, loss = 1.0659
2023-12-05 05:50:04,090 - [2023-12-05 05:50:04] iter = 02950, loss = 1.0841
2023-12-05 05:50:12,550 - [2023-12-05 05:50:12] iter = 02960, loss = 1.0713
2023-12-05 05:50:21,048 - [2023-12-05 05:50:21] iter = 02970, loss = 1.0794
2023-12-05 05:50:29,459 - [2023-12-05 05:50:29] iter = 02980, loss = 1.1069
2023-12-05 05:50:38,009 - [2023-12-05 05:50:38] iter = 02990, loss = 1.0621
2023-12-05 05:50:46,246 - [2023-12-05 05:50:46] iter = 03000, loss = 1.1407
2023-12-05 05:50:54,480 - [2023-12-05 05:50:54] iter = 03010, loss = 1.0270
2023-12-05 05:51:02,849 - [2023-12-05 05:51:02] iter = 03020, loss = 1.0693
2023-12-05 05:51:11,224 - [2023-12-05 05:51:11] iter = 03030, loss = 1.0553
2023-12-05 05:51:19,597 - [2023-12-05 05:51:19] iter = 03040, loss = 1.0360
2023-12-05 05:51:28,123 - [2023-12-05 05:51:28] iter = 03050, loss = 1.0855
2023-12-05 05:51:36,492 - [2023-12-05 05:51:36] iter = 03060, loss = 1.0691
2023-12-05 05:51:44,853 - [2023-12-05 05:51:44] iter = 03070, loss = 1.0804
2023-12-05 05:51:53,154 - [2023-12-05 05:51:53] iter = 03080, loss = 1.1172
2023-12-05 05:52:01,583 - [2023-12-05 05:52:01] iter = 03090, loss = 1.1489
2023-12-05 05:52:09,761 - [2023-12-05 05:52:09] iter = 03100, loss = 1.0776
2023-12-05 05:52:18,012 - [2023-12-05 05:52:18] iter = 03110, loss = 1.0311
2023-12-05 05:52:26,318 - [2023-12-05 05:52:26] iter = 03120, loss = 1.0404
2023-12-05 05:52:34,737 - [2023-12-05 05:52:34] iter = 03130, loss = 1.0978
2023-12-05 05:52:43,108 - [2023-12-05 05:52:43] iter = 03140, loss = 1.1669
2023-12-05 05:52:51,389 - [2023-12-05 05:52:51] iter = 03150, loss = 1.0918
2023-12-05 05:52:59,799 - [2023-12-05 05:52:59] iter = 03160, loss = 1.1088
2023-12-05 05:53:08,095 - [2023-12-05 05:53:08] iter = 03170, loss = 1.0823
2023-12-05 05:53:16,541 - [2023-12-05 05:53:16] iter = 03180, loss = 1.0704
2023-12-05 05:53:24,816 - [2023-12-05 05:53:24] iter = 03190, loss = 1.1043
2023-12-05 05:53:33,294 - [2023-12-05 05:53:33] iter = 03200, loss = 1.0900
2023-12-05 05:53:41,801 - [2023-12-05 05:53:41] iter = 03210, loss = 1.0745
2023-12-05 05:53:50,111 - [2023-12-05 05:53:50] iter = 03220, loss = 1.0768
2023-12-05 05:53:58,434 - [2023-12-05 05:53:58] iter = 03230, loss = 1.1188
2023-12-05 05:54:06,742 - [2023-12-05 05:54:06] iter = 03240, loss = 1.0901
2023-12-05 05:54:15,125 - [2023-12-05 05:54:15] iter = 03250, loss = 1.0585
2023-12-05 05:54:23,358 - [2023-12-05 05:54:23] iter = 03260, loss = 1.0869
2023-12-05 05:54:31,732 - [2023-12-05 05:54:31] iter = 03270, loss = 1.0871
2023-12-05 05:54:40,216 - [2023-12-05 05:54:40] iter = 03280, loss = 1.0813
2023-12-05 05:54:48,667 - [2023-12-05 05:54:48] iter = 03290, loss = 1.0929
2023-12-05 05:54:57,078 - [2023-12-05 05:54:57] iter = 03300, loss = 1.0673
2023-12-05 05:55:05,362 - [2023-12-05 05:55:05] iter = 03310, loss = 1.0632
2023-12-05 05:55:13,746 - [2023-12-05 05:55:13] iter = 03320, loss = 1.0491
2023-12-05 05:55:22,056 - [2023-12-05 05:55:22] iter = 03330, loss = 1.0793
2023-12-05 05:55:30,291 - [2023-12-05 05:55:30] iter = 03340, loss = 1.0942
2023-12-05 05:55:38,464 - [2023-12-05 05:55:38] iter = 03350, loss = 1.1183
2023-12-05 05:55:46,745 - [2023-12-05 05:55:46] iter = 03360, loss = 1.0735
2023-12-05 05:55:55,066 - [2023-12-05 05:55:55] iter = 03370, loss = 1.0694
2023-12-05 05:56:03,404 - [2023-12-05 05:56:03] iter = 03380, loss = 0.9982
2023-12-05 05:56:11,680 - [2023-12-05 05:56:11] iter = 03390, loss = 1.0519
2023-12-05 05:56:20,076 - [2023-12-05 05:56:20] iter = 03400, loss = 1.0191
2023-12-05 05:56:28,369 - [2023-12-05 05:56:28] iter = 03410, loss = 1.0443
2023-12-05 05:56:36,775 - [2023-12-05 05:56:36] iter = 03420, loss = 1.0752
2023-12-05 05:56:45,079 - [2023-12-05 05:56:45] iter = 03430, loss = 1.0698
2023-12-05 05:56:53,504 - [2023-12-05 05:56:53] iter = 03440, loss = 1.0845
2023-12-05 05:57:01,985 - [2023-12-05 05:57:01] iter = 03450, loss = 1.0784
2023-12-05 05:57:10,310 - [2023-12-05 05:57:10] iter = 03460, loss = 1.1477
2023-12-05 05:57:18,770 - [2023-12-05 05:57:18] iter = 03470, loss = 1.1035
2023-12-05 05:57:27,018 - [2023-12-05 05:57:27] iter = 03480, loss = 1.0932
2023-12-05 05:57:35,331 - [2023-12-05 05:57:35] iter = 03490, loss = 1.0692
2023-12-05 05:57:43,652 - [2023-12-05 05:57:43] iter = 03500, loss = 1.0419
2023-12-05 05:57:51,864 - [2023-12-05 05:57:51] iter = 03510, loss = 1.0638
2023-12-05 05:58:00,131 - [2023-12-05 05:58:00] iter = 03520, loss = 1.0903
2023-12-05 05:58:08,552 - [2023-12-05 05:58:08] iter = 03530, loss = 1.1330
2023-12-05 05:58:16,962 - [2023-12-05 05:58:16] iter = 03540, loss = 1.0477
2023-12-05 05:58:25,372 - [2023-12-05 05:58:25] iter = 03550, loss = 1.0736
2023-12-05 05:58:33,631 - [2023-12-05 05:58:33] iter = 03560, loss = 1.0754
2023-12-05 05:58:41,947 - [2023-12-05 05:58:41] iter = 03570, loss = 1.0929
2023-12-05 05:58:50,247 - [2023-12-05 05:58:50] iter = 03580, loss = 1.1395
2023-12-05 05:58:58,625 - [2023-12-05 05:58:58] iter = 03590, loss = 1.0578
2023-12-05 05:59:06,983 - [2023-12-05 05:59:06] iter = 03600, loss = 1.1163
2023-12-05 05:59:15,325 - [2023-12-05 05:59:15] iter = 03610, loss = 1.1252
2023-12-05 05:59:23,694 - [2023-12-05 05:59:23] iter = 03620, loss = 1.1135
2023-12-05 05:59:32,127 - [2023-12-05 05:59:32] iter = 03630, loss = 1.0712
2023-12-05 05:59:40,464 - [2023-12-05 05:59:40] iter = 03640, loss = 1.1286
2023-12-05 05:59:48,836 - [2023-12-05 05:59:48] iter = 03650, loss = 1.0288
2023-12-05 05:59:57,139 - [2023-12-05 05:59:57] iter = 03660, loss = 1.0306
2023-12-05 06:00:05,319 - [2023-12-05 06:00:05] iter = 03670, loss = 1.0465
2023-12-05 06:00:13,715 - [2023-12-05 06:00:13] iter = 03680, loss = 1.0945
2023-12-05 06:00:22,012 - [2023-12-05 06:00:22] iter = 03690, loss = 1.0175
2023-12-05 06:00:30,401 - [2023-12-05 06:00:30] iter = 03700, loss = 1.1014
2023-12-05 06:00:38,725 - [2023-12-05 06:00:38] iter = 03710, loss = 1.0621
2023-12-05 06:00:47,054 - [2023-12-05 06:00:47] iter = 03720, loss = 1.1135
2023-12-05 06:00:55,456 - [2023-12-05 06:00:55] iter = 03730, loss = 1.0708
2023-12-05 06:01:03,809 - [2023-12-05 06:01:03] iter = 03740, loss = 1.1030
2023-12-05 06:01:12,205 - [2023-12-05 06:01:12] iter = 03750, loss = 1.1139
2023-12-05 06:01:20,562 - [2023-12-05 06:01:20] iter = 03760, loss = 1.0842
2023-12-05 06:01:28,893 - [2023-12-05 06:01:28] iter = 03770, loss = 1.0677
2023-12-05 06:01:37,202 - [2023-12-05 06:01:37] iter = 03780, loss = 1.0553
2023-12-05 06:01:45,615 - [2023-12-05 06:01:45] iter = 03790, loss = 1.0626
2023-12-05 06:01:53,925 - [2023-12-05 06:01:53] iter = 03800, loss = 1.0813
2023-12-05 06:02:02,422 - [2023-12-05 06:02:02] iter = 03810, loss = 1.0744
2023-12-05 06:02:10,874 - [2023-12-05 06:02:10] iter = 03820, loss = 1.0511
2023-12-05 06:02:19,271 - [2023-12-05 06:02:19] iter = 03830, loss = 1.1211
2023-12-05 06:02:27,654 - [2023-12-05 06:02:27] iter = 03840, loss = 1.0671
2023-12-05 06:02:35,878 - [2023-12-05 06:02:35] iter = 03850, loss = 1.1054
2023-12-05 06:02:44,166 - [2023-12-05 06:02:44] iter = 03860, loss = 1.0458
2023-12-05 06:02:52,450 - [2023-12-05 06:02:52] iter = 03870, loss = 1.0856
2023-12-05 06:03:00,870 - [2023-12-05 06:03:00] iter = 03880, loss = 1.0785
2023-12-05 06:03:09,261 - [2023-12-05 06:03:09] iter = 03890, loss = 1.0835
2023-12-05 06:03:17,557 - [2023-12-05 06:03:17] iter = 03900, loss = 1.0716
2023-12-05 06:03:25,953 - [2023-12-05 06:03:25] iter = 03910, loss = 1.1243
2023-12-05 06:03:34,292 - [2023-12-05 06:03:34] iter = 03920, loss = 1.0535
2023-12-05 06:03:42,815 - [2023-12-05 06:03:42] iter = 03930, loss = 1.0940
2023-12-05 06:03:51,189 - [2023-12-05 06:03:51] iter = 03940, loss = 1.1399
2023-12-05 06:03:59,499 - [2023-12-05 06:03:59] iter = 03950, loss = 1.0578
2023-12-05 06:04:07,777 - [2023-12-05 06:04:07] iter = 03960, loss = 1.0749
2023-12-05 06:04:16,188 - [2023-12-05 06:04:16] iter = 03970, loss = 1.0246
2023-12-05 06:04:24,722 - [2023-12-05 06:04:24] iter = 03980, loss = 1.0654
2023-12-05 06:04:32,982 - [2023-12-05 06:04:32] iter = 03990, loss = 1.0951
2023-12-05 06:04:40,311 - -------------------------
Evaluation
model_train = ConvNet, model_eval = ConvNet, iteration = 4000
2023-12-05 06:04:40,311 - DSA augmentation strategy: 
 color_crop_cutout_flip_scale_rotate
2023-12-05 06:04:40,312 - DSA augmentation parameters: 
 {'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5, 'Siamese': True, 'latestseed': 80111}
2023-12-05 06:08:31,414 - [2023-12-05 06:08:31] Evaluate_00: epoch = 0500 train time = 228 s train loss = 0.045945 train acc = 0.9933, test acc = 0.3043
2023-12-05 06:12:22,586 - [2023-12-05 06:12:22] Evaluate_01: epoch = 0500 train time = 228 s train loss = 0.044064 train acc = 0.9945, test acc = 0.3048
2023-12-05 06:16:13,800 - [2023-12-05 06:16:13] Evaluate_02: epoch = 0500 train time = 228 s train loss = 0.045398 train acc = 0.9959, test acc = 0.3048
